{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "bbg_R6QGtu81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "1qQvaeq_woO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "6agcr4rlYTyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLbCI2hLKd7T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import gensim\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WvOv9BHgvroM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "4viiNN9CwmCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_df = pd.read_csv('./drive/MyDrive/datasets/cyberbullying_tweets.csv')"
      ],
      "metadata": {
        "id": "xAtsEEfmKqpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_df.tail()"
      ],
      "metadata": {
        "id": "qv__oDjwLrpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_df = bully_df.rename(columns={'tweet_text':'tweet','cyberbullying_type':'type'})"
      ],
      "metadata": {
        "id": "rK7eGalzMyI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_df.head()"
      ],
      "metadata": {
        "id": "IgRWiOquNWe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_df['tweet'] = bully_df['tweet'].apply(lambda x: re.sub(r'@\\w+', '', x).strip())"
      ],
      "metadata": {
        "id": "78N_Ju5OmvEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_df.head()"
      ],
      "metadata": {
        "id": "2i8p2hO4nYqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleantxt(txt):\n",
        "    stpw = stopwords.words('english')\n",
        "\n",
        "    stpw.extend(['www','http','utc'])\n",
        "    stpw = set(stpw)\n",
        "    txt = re.sub(r\"\\n\", \" \", txt)\n",
        "    txt = re.sub(\"[\\<\\[].*?[\\>\\]]\", \" \", txt)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(r\"[^a-zA-Z ]\", \" \", txt)\n",
        "    txt = re.sub(r\"\\b\\w{1,3}\\b\", \" \",txt)\n",
        "    txt = \" \".join([x for x in txt.split() if x not in stpw])\n",
        "    return txt"
      ],
      "metadata": {
        "id": "ioYON-2A5QVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_df['tweet'] = bully_df['tweet'].apply(cleantxt)"
      ],
      "metadata": {
        "id": "zjOeUX7G5dmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_df['tweet'] = bully_df['tweet'].apply(lambda x: remove_stopwords(x))"
      ],
      "metadata": {
        "id": "Wi_caF7pyP7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_df.tail(10)"
      ],
      "metadata": {
        "id": "Ff8MhhkFvErM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_sentence(sentence):\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in tokens]\n",
        "    return ' '.join(lemmatized_words)"
      ],
      "metadata": {
        "id": "X-PI3cyswfeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_df['tweet'] = bully_df['tweet'].apply(lemmatize_sentence)"
      ],
      "metadata": {
        "id": "KW50QMqYxbft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_df.tail(10)"
      ],
      "metadata": {
        "id": "xmEJCFYTyveB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_df.tail(10)"
      ],
      "metadata": {
        "id": "cMSApaanRz3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "negative_words = ' '.join([text for text in bully_df['tweet'][bully_df['type'] != 'not_cyberbullying']])\n",
        "wordcloud = WordCloud(width=800, height=500,\n",
        "random_state=21, max_font_size=110).generate(negative_words)\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dizrm6CF2kC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_df['tweet'] = bully_df['tweet'].apply(lambda x: x.split())\n",
        "# bully_df['tweet'] = bully_df['tweet'].apply(lambda x: ([w for w in x if len(w)>=3]))\n",
        "# bully_df['tweetcnn'] = bully_df['tweet'].apply(lambda x: ' '.)"
      ],
      "metadata": {
        "id": "QYcyGTAn5RPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_df.tail(10)"
      ],
      "metadata": {
        "id": "sW5JdP8n5ang"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gender religion age ethnicity other_cyberbullying\n",
        "not_bully_df = bully_df[bully_df['type'] == 'not_cyberbullying']\n",
        "gender_bully_df = bully_df[bully_df['type'] == 'gender']\n",
        "religion_bully_df = bully_df[bully_df['type'] == 'religion']\n",
        "age_bully_df = bully_df[bully_df['type'] == 'age']\n",
        "ethnicity_bully_df = bully_df[bully_df['type'] == 'ethnicity']\n",
        "other_bully_df = bully_df[bully_df['type'] == 'other_cyberbullying']\n",
        "all_bully_df = bully_df[bully_df['type'] != 'not_cyberbullying']\n",
        "\n",
        "print(not_bully_df.shape)\n",
        "print(gender_bully_df.shape)\n",
        "print(religion_bully_df.shape)\n",
        "print(age_bully_df.shape)\n",
        "print(ethnicity_bully_df.shape)\n",
        "print(other_bully_df.shape)\n",
        "print(all_bully_df.shape)"
      ],
      "metadata": {
        "id": "yHyA-P1YXi2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_bully_df.tail()"
      ],
      "metadata": {
        "id": "ZD49zXcIlvHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_not_bully_df = not_bully_df.sample(n=7000, random_state=42)\n",
        "sampled_gender_bully_df = gender_bully_df.sample(n=1750, random_state=42)\n",
        "sampled_age_bully_df = age_bully_df.sample(n=1750, random_state=42)\n",
        "sampled_religion_bully_df = religion_bully_df.sample(n=1750, random_state=42)\n",
        "sampled_ethnicity_bully_df = ethnicity_bully_df.sample(n=1750, random_state=42)\n",
        "sampled_other_bully_df = other_bully_df.sample(n=1500, random_state=42)\n",
        "\n",
        "sampled2_not_bully_df = not_bully_df.sample(n=3000, random_state=42)\n",
        "sampled2_gender_bully_df = gender_bully_df.sample(n=600, random_state=42)\n",
        "sampled2_age_bully_df = age_bully_df.sample(n=600, random_state=42)\n",
        "sampled2_religion_bully_df = religion_bully_df.sample(n=600, random_state=42)\n",
        "sampled2_ethnicity_bully_df = ethnicity_bully_df.sample(n=600, random_state=42)\n",
        "sampled2_other_bully_df = other_bully_df.sample(n=600, random_state=42)"
      ],
      "metadata": {
        "id": "DSVnf6TiayHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_gender_bully_df.shape"
      ],
      "metadata": {
        "id": "N4wassWhmlxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_gender_bully_df.tail()"
      ],
      "metadata": {
        "id": "tjcB7Thcc9Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.concat([sampled_not_bully_df, sampled_gender_bully_df, sampled_age_bully_df, sampled_religion_bully_df, sampled_ethnicity_bully_df], ignore_index=True)\n",
        "final_df['tweet'] = final_df['tweet'].apply(lambda x: ([w for w in x if len(w)>=3]))"
      ],
      "metadata": {
        "id": "l6EbatYVdj5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final2_df = pd.concat([sampled2_not_bully_df, sampled2_gender_bully_df, sampled2_age_bully_df, sampled2_religion_bully_df, sampled2_ethnicity_bully_df, sampled2_other_bully_df], ignore_index=True)\n",
        "final2_df['tweet'] = final2_df['tweet'].apply(lambda x: ([w for w in x if len(w)>=3]))"
      ],
      "metadata": {
        "id": "KQV57lCVbBL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_df['tweet'])"
      ],
      "metadata": {
        "id": "dB4CBFJKBSQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final2_df.loc[final2_df['type']!='not_cyberbullying','type'] = 'yes'\n",
        "final2_df.loc[final2_df['type']=='not_cyberbullying','type'] = 'no'"
      ],
      "metadata": {
        "id": "G5IAuGQ6ewbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def allign(text):\n",
        "#   while len(text)<5:\n",
        "#     text.append('<oov>')\n",
        "#   return text\n",
        "\n",
        "# final_df['tweet'] = final_df['tweet'].apply(allign)\n",
        "# final2_df['tweet'] = final2_df['tweet'].apply(allign)"
      ],
      "metadata": {
        "id": "G_m7Hdtsvi80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {'not_cyberbullying': 0, 'gender': 1, 'age': 1, 'ethnicity': 1, 'religion':1, 'other_cyberbullying':1}\n",
        "mapping2 = {'yes': 1, 'no': 0}"
      ],
      "metadata": {
        "id": "U-CCjtGAoq5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.tail(20)"
      ],
      "metadata": {
        "id": "5vBSnJ_atL0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df['type'] = final_df['type'].map(mapping)\n",
        "final2_df['type'] = final2_df['type'].map(mapping2)"
      ],
      "metadata": {
        "id": "nmFaz-sRpZ6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.tail()"
      ],
      "metadata": {
        "id": "1kzlydm-d0mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.shape"
      ],
      "metadata": {
        "id": "MLrxzJXinJIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get3gram(text):\n",
        "  arr = []\n",
        "  if len(text)<3:\n",
        "    arr.append('-'.join(text))\n",
        "  for i in range(2,len(text)):\n",
        "    substr = text[i-2:i+1]\n",
        "    st = '-'.join(substr)\n",
        "    arr.append(st)\n",
        "  return arr\n",
        "\n",
        "final_df['tweet3gram'] = final_df['tweet'].apply(get3gram)\n",
        "final2_df['tweet3gram'] = final2_df['tweet'].apply(get3gram)"
      ],
      "metadata": {
        "id": "eqHi96-WlArS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.tail(20)"
      ],
      "metadata": {
        "id": "C6yJ6ChuJW7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.shape"
      ],
      "metadata": {
        "id": "J389EPajF-we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 gram multiple type"
      ],
      "metadata": {
        "id": "T235jdYeFbCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.corpora import Dictionary\n",
        "\n",
        "dictionary = Dictionary(final_df['tweet'])\n",
        "corpus = [dictionary.doc2bow(text) for text in final_df['tweet']]\n",
        "tfidf = gensim.models.TfidfModel(corpus)"
      ],
      "metadata": {
        "id": "R1iaUyey5ea9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_docs = len(corpus)\n",
        "num_terms = len(dictionary)\n",
        "\n",
        "tfidf_matrix = np.zeros((num_docs, num_terms))\n",
        "\n",
        "for doc_index, doc in enumerate(tfidf[corpus]):\n",
        "    for word_id, score in doc:\n",
        "        tfidf_matrix[doc_index, word_id] = score\n",
        "\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix, columns=[dictionary[i] for i in range(num_terms)])\n"
      ],
      "metadata": {
        "id": "krOB7ly99DdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_df"
      ],
      "metadata": {
        "id": "qgeTlrG3-MKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tfidf_matrix\n",
        "y = final_df['type'].values"
      ],
      "metadata": {
        "id": "Yw-X44RPDIM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((y == 0).sum())\n",
        "print((y == 1).sum())\n",
        "X.shape"
      ],
      "metadata": {
        "id": "hho7LODYV6w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
      ],
      "metadata": {
        "id": "wpCkPYo-I2bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = SVC(kernel='rbf', C=4, probability=True)\n",
        "model_svm.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "vAQ1OLAwJg8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_svm = model_svm.predict(X_test)\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred_svm)\n",
        "cnf_matrix"
      ],
      "metadata": {
        "id": "dmuGBlXhBjV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=['no_bully', 'bully'] # name  of classes\n",
        "fig, ax = plt.subplots(figsize=(3,3))\n",
        "\n",
        "# create heatmap\n",
        "sns.heatmap(cnf_matrix, annot=True, cmap=\"YlGnBu\", fmt='g', cbar=False)\n",
        "ax.set_xticklabels(class_names, rotation=45, ha='right')  # Rotate x-ticks for readability\n",
        "ax.set_yticklabels(class_names, rotation=0)\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label(svm)')"
      ],
      "metadata": {
        "id": "G77WIXEZBYzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = ['no_bully', 'bully']\n",
        "print(classification_report(y_test, y_pred_svm, target_names=target_names))"
      ],
      "metadata": {
        "id": "1Yh6qH6GKouY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = model_svm.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "XzdNgzPCWj25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yy=np.eye(2)[y_test]\n",
        "\n",
        "# Plot ROC curve for each class\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "for i in range(2):\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr, tpr, _ = roc_curve(yy[:,i], y_score[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# Plot the diagonal line for random guessing\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')\n",
        "\n",
        "# Label the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Each Class')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TiXOqDgqPsse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP = cnf_matrix[0, 0]\n",
        "FN = cnf_matrix[0, 1]\n",
        "FP = cnf_matrix[1, 0]\n",
        "TN = cnf_matrix[1, 1]\n",
        "\n",
        "recall = TP / (TP + FN)\n",
        "\n",
        "precision = TP / (TP + FP)\n",
        "\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1_score:.2f}\")"
      ],
      "metadata": {
        "id": "8oZwhiYo9yeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for c=4, poly kerneel accuracy 0.53 & rbf kernel accuracy 0.78\n",
        "# for c=3  poly kernel accuracy  & rbf kernel accuracy 0.78\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(f\"Model Accuracy: {accuracy_svm:.2f}\")"
      ],
      "metadata": {
        "id": "iATEbd6FJjWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "logreg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "vfpfH8ZK6bL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = logreg.predict(X_test)\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cnf_matrix"
      ],
      "metadata": {
        "id": "z5esUTAx7N_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=['no_bully', 'bully'] # name  of classes\n",
        "fig, ax = plt.subplots(figsize=(3,3))\n",
        "\n",
        "# create heatmap\n",
        "sns.heatmap(cnf_matrix, annot=True, cmap=\"YlGnBu\", fmt='g', cbar=False)\n",
        "ax.set_xticklabels(class_names, rotation=45, ha='right')  # Rotate x-ticks for readability\n",
        "ax.set_yticklabels(class_names, rotation=0)\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label(logistic)')\n"
      ],
      "metadata": {
        "id": "_LCbKK5s7Hkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = ['no_bully', 'bully']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "7ScCu85uAK9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP = cnf_matrix[0, 0]\n",
        "FN = cnf_matrix[0, 1]\n",
        "FP = cnf_matrix[1, 0]\n",
        "TN = cnf_matrix[1, 1]\n",
        "\n",
        "recall = TP / (TP + FN)\n",
        "\n",
        "precision = TP / (TP + FP)\n",
        "\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1_score:.2f}\")"
      ],
      "metadata": {
        "id": "Tw3z1fxG9vqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = logreg.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "rZQvshv5nfl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "y_test_one_hot = label_binarize(y_test, classes=[0, 1,2,3,4])\n",
        "\n",
        "for i in range(2):\n",
        "    fpr, tpr, _ = roc_curve(y_test_one_hot[:, i], y_score[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Each Class')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-TDDSiidRKhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logacc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {logacc:.2f}\")"
      ],
      "metadata": {
        "id": "K4v8ZZq1BJav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "booster = GradientBoostingClassifier(loss='log_loss', n_estimators=100, learning_rate=0.1, max_depth=3)\n",
        "booster.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Nc4dNBkRtLnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = booster.predict(X_test)\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cnf_matrix"
      ],
      "metadata": {
        "id": "Z6-iUtXKAGJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=['no_bully', 'bully'] # name  of classes\n",
        "fig, ax = plt.subplots(figsize=(3,3))\n",
        "\n",
        "# create heatmap\n",
        "sns.heatmap(cnf_matrix, annot=True, cmap=\"YlGnBu\", fmt='g', cbar=False)\n",
        "ax.set_xticklabels(class_names, rotation=45, ha='right')  # Rotate x-ticks for readability\n",
        "ax.set_yticklabels(class_names, rotation=0)\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label(grad boosting)')\n"
      ],
      "metadata": {
        "id": "3VeRZGaYAcAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = ['no_bully', 'bully']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "_PMZ9f0VA95k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP = cnf_matrix[0, 0]\n",
        "FN = cnf_matrix[0, 1]\n",
        "FP = cnf_matrix[1, 0]\n",
        "TN = cnf_matrix[1, 1]\n",
        "\n",
        "recall = TP / (TP + FN)\n",
        "\n",
        "precision = TP / (TP + FP)\n",
        "\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1_score:.2f}\")"
      ],
      "metadata": {
        "id": "V14hJ7uv9qVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_score = booster.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "LwLobIHVBIWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_score"
      ],
      "metadata": {
        "id": "q7zydm8pSxJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_one_hot = label_binarize(y_test, classes=[0,1,2,3,4])\n",
        "y_test_one_hot"
      ],
      "metadata": {
        "id": "q3XgT_RmS2Nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "y_test_one_hot = label_binarize(y_test, classes=[0, 1,2,3,4])\n",
        "\n",
        "for i in range(2):\n",
        "    fpr, tpr, _ = roc_curve(y_test_one_hot[:, i], y_score[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Each Class')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IwkMwOT5RriS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boostacc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {boostacc:.2f}\")"
      ],
      "metadata": {
        "id": "WlAq_gyhCQ6S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}